---
title: 'Homework: iterative method'
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r setup, include = FALSE}
source(file.path("..", "R", "util.R"))
required_packages <- c('RSpectra')
install_and_load_packages(required_packages)
```

# Problem 1
Auto regressive processes can be viewed as a discrete analog of Ornsteinâ€“Uhlenbeck process &mdash; which coincides with Gaussian process based on an exponential covariance matrix &mdash; and hence is an example of Gaussian Markov random fields.
For instance, stationary lag-1 auto-regressive process 
$$x_t = \phi x_{t - 1} + \sqrt{1 - \phi^2} \, \epsilon_t, 
  \quad x_0 \sim \mathcal{N}(0, 1), 
  \quad \epsilon_t \mathbin{\overset{\small \textrm{i.i.d.}}{\sim}} \mathcal{N}(0, 1)$$
has the _tri-diagonal_ precision matrix
$$\boldsymbol{\Sigma}^{-1} = \frac{1}{1 - \phi^2} 
  \begin{bmatrix} 
  1 & -\phi & 0 & & & \ldots & 0 \\
  -\phi & 1 + \phi^2 & -\phi & 0 & & & \vdots \\
  0 & -\phi & 1 + \phi^2 & -\phi & 0 & & \\
    & & \ddots & \ddots & \ddots & & \\
    & & 0 & -\phi & 1 + \phi^2 & -\phi & 0 \\
  \vdots & &   & 0 & -\phi & 1 + \phi^2 & -\phi \\
  0 & \ldots &   &   & 0 & -\phi & 1\\
  \end{bmatrix}.$$
More generally, a lag-$k$ (non-stationary) auto-regressive process has a _banded_ precision matrix with bandwidth $k$.

Implement a fast matrix-vector $\boldsymbol{v} \to \boldsymbol{\Sigma}^{-1} \boldsymbol{v}$ operation, exploiting the structure of the AR-1 precision matrix.
Then use this function to find the top 10 principal components of $\boldsymbol{\Sigma}$ (not $\boldsymbol{\Sigma}^{-1}$) via Lanczos algorithm provided via `RSpectra::eigs_sym`.

```{r}
ar_length <- 4096
auto_corr <- .9 # Corresponds to `\phi` above

ar_precision_matvec <- function(v, auto_corr) {
  # Fill in: note that you can vectorize the calculation and do *not* need a for-loop. 
  # (Hint: how would you efficiently carry out a matrix-vector operation if the matrix has non-zero entries only along the sub or super diagonal?)
  
  # get length of vector
  n <- length(v)
  # calculate first element manually
  elem_1 <- v[1] - auto_corr * v[2]
  # calculate last element manually
  elem_n <- v[n] - auto_corr * v[n - 1]
  # calculate middle elements (vectorized)
  elem_backone <- -1 * auto_corr * v[1:(n-2)]
  elem_middle <- (1 + auto_corr^2) * v[2:(n-1)]
  elem_forwardone <- -1 * auto_corr * v[3:n]
  # add vectors
  elems <- elem_backone + elem_middle + elem_forwardone
  
  # combine into full vector (including first and last element)
  elems_all <- c(elem_1, elems, elem_n)
  
  # divide by constant
  elems / (1 - auto_corr^2)
}

ar_eig <- eigs_sym(
  ar_precision_matvec, args = auto_corr,
  # Fill in
  n = ar_length, 
  k = 10, 
  # note: smallest eigenvalues since using precision matrix
  which = "SM", 
  opts = list(
    ncv = 100, # Spectrum distribution of AR-1 process is not very spread out on the extreme ends and is actually a hard case for Lanczos. So it helps to have more Lanczos vectors than the default for faster convergence.
    maxitr = 10^3, # Cap it just in case
    retvec = TRUE # More efficient to do without eigenvectors when not needed
  ),
)

# output
str(ar_eig)
ar_eig$values
head(ar_eig$vectors)
```

Now, directly compute the eigen decomposition of $\boldsymbol{\Sigma}$ (not $\boldsymbol{\Sigma}^{-1}$) and compare its output with the principal components and associated variances found via Lancsoz algorithm.

```{r}
# Fill in

# first calculate the covariance matrix
# which has entries Sigma_ij = phi ^ (t_j - t_i)
exponents <- as.matrix(dist(1:ar_length))
Sigma <- auto_corr^exponents
# check
Sigma[1:10, 1:10]

# eigen decomposition
eig <- eigen(Sigma)

# output
str(eig)

# compare eigenvalues
eig$values[1:10]
# compare with previous (note inverse)
1/ar_eig$values
```

**Remark:** 
For banded matrices, there actually are even more efficient approaches.
To get a sense of special routines available for banded matrices, you can take a look at `*_banded` functions in [SciPy's linear algebra routines](https://docs.scipy.org/doc/scipy/reference/linalg.html).
Even those functions represent only a subset of available numerical linear algebra techniques; see
[LAPACK documentation for SVD](https://www.netlib.org/lapack/lug/node32.html) for example.
